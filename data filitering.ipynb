{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors,MolStandardize,AllChem,rdMolDescriptors\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('**.csv')) # put your own data path\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate molecular fingerprint\n",
    "def get_fps(smi_list):\n",
    "    fps = []\n",
    "    for i in range(len(smi_list)):\n",
    "        mol = Chem.MolFromSmiles(MolStandardize.standardize_smiles(smi_list[i]))\n",
    "        fps2 = AllChem.GetMorganFingerprintAsBitVect(mol,4,nBits=500)\n",
    "        fps.append(fps2)\n",
    "    fps = np.array(fps)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the uncertainty\n",
    "def get_uncertainty(reg,x_train,train_smiles,train_labels,train_predict,x_test,test_smiles,test_labels,test_predict,scaler):\n",
    "    child_estimators = reg.estimators_\n",
    "    train_estimators_results = []\n",
    "    for i in range(len(child_estimators)):\n",
    "        estimator = child_estimators[i]\n",
    "        r = estimator.predict(x_train).reshape(-1,1)\n",
    "        train_estimators_results.append(r)            \n",
    "    train_estimators_results = scaler.inverse_transform(np.concatenate(train_estimators_results,axis=1))\n",
    "    std = np.array(np.std(train_estimators_results,axis=1)).reshape(-1,1)       \n",
    "    train_results = np.concatenate([np.array(train_smiles).reshape(-1,1),np.array(train_labels),train_predict,std],axis=1)\n",
    "    test_estimators_results = []\n",
    "    for i in range(len(child_estimators)):\n",
    "        estimator = child_estimators[i]\n",
    "        r = estimator.predict(x_test).reshape(-1,1)\n",
    "        test_estimators_results.append(r)            \n",
    "    test_estimators_results = scaler.inverse_transform(np.concatenate(test_estimators_results,axis=1))\n",
    "    test_std = np.array(np.std(test_estimators_results,axis=1)).reshape(-1,1)       \n",
    "    test_results = np.concatenate([np.array(test_smiles).reshape(-1,1),np.array(test_labels),test_predict,test_std],axis=1)\n",
    "\n",
    "    M_std = np.median(std)      \n",
    "    record = []    \n",
    "    for row in std:\n",
    "        record.append(np.array(abs(row[0]-M_std)).reshape(-1,1)) \n",
    "    record = np.concatenate(record,axis=0)          \n",
    "    mad = 1.4826*np.median(record)                  \n",
    "    d_c = M_std+3*mad                              \n",
    "    new_train_data = []\n",
    "    culled_train_data = []\n",
    "    for row in train_results:\n",
    "        if float(row[3]) <= d_c:       \n",
    "            new_train_data.append(row.reshape(1,-1))\n",
    "        else:\n",
    "            culled_train_data.append(row.reshape(1,-1))     \n",
    "    new_train_data = np.concatenate(new_train_data,axis=0)\n",
    "    if len(culled_train_data) != 0:\n",
    "        culled_train_data = np.concatenate(culled_train_data,axis=0)\n",
    "    else:\n",
    "        print('no molecule removed')\n",
    "    new_test_data = []\n",
    "    culled_test_data = []\n",
    "    for row in test_results:\n",
    "        if float(row[3]) <= d_c:     \n",
    "            new_test_data.append(row.reshape(1,-1))\n",
    "        else:\n",
    "            culled_test_data.append(row.reshape(1,-1))\n",
    "    try:\n",
    "        new_test_data = np.concatenate(new_test_data,axis=0)\n",
    "    except:\n",
    "        pass\n",
    "    if len(culled_test_data) != 0:\n",
    "        culled_test_data = np.concatenate(culled_test_data,axis=0)\n",
    "    else:\n",
    "        print('no molecule removed')\n",
    "    return new_train_data,new_test_data,culled_train_data,culled_test_data,M_std,d_c,mad\n",
    "\n",
    "\n",
    "# set multiple iteration in each fold\n",
    "def uncertainty_loop(j,loop,train_data,test_data):    \n",
    "    M_std_record , d_c_record ,mad_record = [] , [] , []        \n",
    "    train_data_record , test_data_record = [] , []\n",
    "    culled_train_record , culled_test_record = [] , []\n",
    "    acc_record = []                                                         \n",
    "    train_smiles , test_smiles = list(train_data.iloc[:,0]),list(test_data.iloc[:,0])       \n",
    "    train_labels , test_labels = np.array(train_data.iloc[:,1]).reshape(-1,1),np.array(test_data.iloc[:,1]).reshape(-1,1)\n",
    "    train_scaler = StandardScaler().fit(train_labels.reshape(-1,1))\n",
    "    normed_train = train_scaler.transform(train_labels.reshape(-1,1))          \n",
    "    uncertainty_result = pd.DataFrame()\n",
    "    for i in range(loop):  \n",
    "        x_train,x_test = get_fps(train_smiles),get_fps(test_smiles)       \n",
    "\n",
    "        reg = RandomForestRegressor(n_jobs=30)  \n",
    "        reg  = reg.fit(x_train,normed_train.ravel())\n",
    "        train_predict = train_scaler.inverse_transform(reg.predict(x_train).reshape(-1,1))\n",
    "        test_predict = train_scaler.inverse_transform(reg.predict(x_test).reshape(-1,1))\n",
    "        print('-'*10,i,'-'*10)\n",
    "\n",
    "        r2_train , r2_test = r2_score(train_labels,train_predict) , r2_score(test_labels,test_predict)\n",
    "        mae_train , mae_test = mean_absolute_error(train_labels,train_predict) , mean_absolute_error(test_labels,test_predict)\n",
    "        mse_train , mse_test = mean_squared_error(train_labels,train_predict) , mean_squared_error(test_labels,test_predict)\n",
    "\n",
    "        acc_record.append([r2_train,mae_train,mse_train,r2_test,mae_test,mse_test])\n",
    "        print(r2_train,mae_train,mse_train,'\\n',r2_test,mae_test,mse_test)\n",
    "\n",
    "        new_train_data,new_test_data,culled_train_data,culled_test_data,M_std,d_c,mad = get_uncertainty(reg,x_train,train_smiles,train_labels,train_predict,x_test,test_smiles,test_labels,test_predict,scaler=train_scaler)\n",
    "\n",
    "        print('M',M_std,'MAD',mad,'threshold',d_c)\n",
    "        try:\n",
    "            print('the number of training molecules',new_train_data.shape[0],'the number of test molecules',new_test_data.shape[0])\n",
    "        except:\n",
    "            print('warning: new dataset has no data...')\n",
    "\n",
    "        train_data_record.append(new_train_data)        \n",
    "        test_data_record.append(new_test_data)\n",
    "        culled_train_record.append(culled_train_data)\n",
    "        culled_test_record.append(culled_test_data)\n",
    "\n",
    "        para = np.array([M_std,mad,d_c])\n",
    "        M_std_record.append(M_std)      \n",
    "        d_c_record.append(d_c)   \n",
    "        mad_record.append(mad) \n",
    "\n",
    "\n",
    "        train_smiles , test_smiles = list(new_train_data[:,0]),list(new_test_data[:,0])\n",
    "        train_labels , test_labels = np.array(new_train_data[:,1],dtype=np.float32).reshape(-1,1),np.array(new_test_data[:,1],dtype=np.float32).reshape(-1,1)\n",
    "        train_scaler = StandardScaler().fit(train_labels.reshape(-1,1))       \n",
    "        normed_train = train_scaler.transform(train_labels.reshape(-1,1))      \n",
    "\n",
    "    return M_std_record,d_c_record,mad_record,train_data_record,test_data_record,culled_train_record,culled_test_record,acc_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cv = []\n",
    "test_data_cv = []\n",
    "\n",
    "culled_train_cv = []\n",
    "culled_test_cv = []\n",
    "\n",
    "M_std_cv = []\n",
    "d_c_cv = []\n",
    "mad_c_cv = []\n",
    "\n",
    "acc_cv = []\n",
    "\n",
    "f=1\n",
    "for train, test in kf.split(data):\n",
    "\n",
    "    print('*'*50,f'{f}fold','*'*50)\n",
    "    train_data = pd.DataFrame(data[train])\n",
    "    test_data = pd.DataFrame(data[test])\n",
    "\n",
    "\n",
    "    M_std_record,d_c_record,mad_record,train_data_record,test_data_record,culled_train_record,culled_test_record,acc_record = uncertainty_loop(f,15,train_data,test_data)\n",
    "\n",
    "    culled_train_cv.append(culled_train_record)\n",
    "    culled_test_cv.append(culled_test_record)\n",
    "\n",
    "\n",
    "    train_data_cv.append(train_data_record[-1])\n",
    "    test_data_cv.append(test_data_record[-1])\n",
    "\n",
    "\n",
    "    acc_cv.append(acc_record)\n",
    "\n",
    "\n",
    "    M_std_cv.append(M_std_record)\n",
    "    d_c_cv.append(d_c_record)\n",
    "    mad_c_cv.append(mad_record)\n",
    "    \n",
    "    f+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - fold\n",
    "test1 = test_data_cv[0]\n",
    "test2 = test_data_cv[1]\n",
    "test3 = test_data_cv[2]\n",
    "test4 = test_data_cv[3]\n",
    "test5 = test_data_cv[4]\n",
    "\n",
    "culled_test1 = culled_test_cv[0]\n",
    "culled_test1 = [elem for elem in culled_test1 if len(elem) > 0]\n",
    "culled_test1 = np.concatenate(culled_test1)\n",
    "\n",
    "culled_test2 = culled_test_cv[1]\n",
    "culled_test2 = [elem for elem in culled_test2 if len(elem) > 0]\n",
    "culled_test2 = np.concatenate(culled_test2)\n",
    "\n",
    "culled_test3 = culled_test_cv[2]\n",
    "culled_test3 = [elem for elem in culled_test3 if len(elem) > 0]\n",
    "culled_test3 = np.concatenate(culled_test3)\n",
    "\n",
    "culled_test4 = culled_test_cv[3]\n",
    "culled_test4 = [elem for elem in culled_test4 if len(elem) > 0]\n",
    "culled_test4 = np.concatenate(culled_test4)\n",
    "\n",
    "culled_test5 = culled_test_cv[4]\n",
    "culled_test5 = [elem for elem in culled_test5 if len(elem) > 0]\n",
    "culled_test5 = np.concatenate(culled_test5)\n",
    "\n",
    "\n",
    "all_culled_data = list(list(culled_test1[:,0])+list(culled_test2[:,0])+list(culled_test3[:,0])+list(culled_test4[:,0])+list(culled_test5[:,0])\n",
    "all_culled_data = list(set(all_culled_data))       \n",
    "new_data = []       \n",
    "for row in data:\n",
    "    if row[0] not in all_culled_data:\n",
    "        new_data.append(row.reshape(1,-1))\n",
    "\n",
    "new_data = np.concatenate(new_data,axis=0)\n",
    "\n",
    "pd.DataFrame(new_data).to_csv('**_washed.csv',index=False) # put your own data path  ; 'new_data' is the final high-quality dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
